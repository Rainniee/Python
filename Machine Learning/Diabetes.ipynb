{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Using scikit-learn for Pima Indians Diabetes Data Set\n",
    "\n",
    "What are the features?\n",
    "\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "\n",
    "What is the response?\n",
    "** a qualitative variable indicating whether a patient has diabetes\n",
    "\n",
    "Objective:\n",
    "** Predict based on diagnostic measurements whether a patient has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "data = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant     glucose          bp        skin     insulin         bmi  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age       label  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing X and y using pandas\n",
    "feature_cols = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age']\n",
    "X = data[feature_cols]\n",
    "y = data.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import linear regression model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instantiate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data (learn the coefficients)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.38919421]\n",
      "[[  1.18771258e-01   2.86935095e-02  -1.88999930e-02  -1.95631010e-03\n",
      "   -2.16032395e-04   5.42091884e-02   4.81916148e-01   3.52888988e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use statsmodels module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamliu/anaconda2/envs/py36/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   R-squared:                       0.303\n",
      "Model:                            OLS   Adj. R-squared:                  0.296\n",
      "Method:                 Least Squares   F-statistic:                     41.29\n",
      "Date:                Fri, 23 Feb 2018   Prob (F-statistic):           7.36e-55\n",
      "Time:                        20:02:39   Log-Likelihood:                -381.91\n",
      "No. Observations:                 768   AIC:                             781.8\n",
      "Df Residuals:                     759   BIC:                             823.6\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.8539      0.085     -9.989      0.000      -1.022      -0.686\n",
      "pregnant       0.0206      0.005      4.014      0.000       0.011       0.031\n",
      "glucose        0.0059      0.001     11.493      0.000       0.005       0.007\n",
      "bp            -0.0023      0.001     -2.873      0.004      -0.004      -0.001\n",
      "skin           0.0002      0.001      0.139      0.890      -0.002       0.002\n",
      "insulin       -0.0002      0.000     -1.205      0.229      -0.000       0.000\n",
      "bmi            0.0132      0.002      6.344      0.000       0.009       0.017\n",
      "pedigree       0.1472      0.045      3.268      0.001       0.059       0.236\n",
      "age            0.0026      0.002      1.693      0.091      -0.000       0.006\n",
      "==============================================================================\n",
      "Omnibus:                       41.539   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.183\n",
      "Skew:                           0.395   Prob(JB):                     1.69e-07\n",
      "Kurtosis:                       2.408   Cond. No.                     1.10e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.1e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions on the testing set\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "# If the probability >0.5 -> class Label into 1; \n",
    "# if the probability <0.5 -> class Label into 0\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44203825,  0.37920023,  0.23397337,  0.06048765,  0.22660355,\n",
       "        0.27505632,  0.37538901,  0.17940593,  0.16629588,  0.21650141,\n",
       "        0.41405121,  0.10483651,  0.93398949,  0.68959899,  0.08557689,\n",
       "        0.67203211,  0.2442347 ,  0.31985908,  0.27401652,  0.22544739,\n",
       "        0.3928777 ,  0.17899496,  0.93201504,  0.33348528,  0.11222   ,\n",
       "        0.37034565,  0.20082997,  0.71906745,  0.10666626,  0.50094894,\n",
       "        0.36721848,  0.47522333,  0.10239179,  0.6203118 ,  0.16212279,\n",
       "        0.50139533,  0.14297237,  0.21590919,  0.14241405,  0.55543825,\n",
       "        0.21925706,  0.13264709,  0.06834866,  0.25829811,  0.11942675,\n",
       "        0.05838127,  0.70872191,  0.77163854,  0.14787205,  0.18601007,\n",
       "        0.05207744,  0.22407674,  0.81339815,  0.09728613,  0.64060244,\n",
       "        0.13783438,  0.70757171,  0.33240479,  0.49002563,  0.20417538,\n",
       "        0.59313131,  0.07441367,  0.72030842,  0.22524338,  0.29423962,\n",
       "        0.1720502 ,  0.02083531,  0.27987901,  0.66190391,  0.56858336,\n",
       "        0.84442119,  0.6417145 ,  0.52209502,  0.04236197,  0.63914187,\n",
       "        0.33513572,  0.60470835,  0.34236513,  0.19397215,  0.61149444,\n",
       "        0.49496165,  0.29942588,  0.39051809,  0.33300281,  0.21646604,\n",
       "        0.59207574,  0.54635693,  0.34022481,  0.2721035 ,  0.36218176,\n",
       "        0.21553398,  0.07583643,  0.28558989,  0.12295449,  0.72610308,\n",
       "        0.48348695,  0.3134028 ,  0.21718854,  0.73682354,  0.19749787,\n",
       "        0.18937349,  0.38623168,  0.54670578,  0.31045104,  0.16894808,\n",
       "        0.11383825,  0.51690343,  0.52739597,  0.24068807,  0.14976133,\n",
       "        0.41551622,  0.08694365,  0.38362537,  0.21302443,  0.0312866 ,\n",
       "        0.12207676,  0.16475296,  0.38705051,  0.28121362,  0.32249635,\n",
       "        0.22251722,  0.80677589,  0.33551376,  0.22895948,  0.21159539,\n",
       "        0.16494593,  0.26203722,  0.36740722,  0.59499228,  0.26094812,\n",
       "        0.88946254,  0.06078509,  0.34368225,  0.38361074,  0.21153312,\n",
       "        0.30905246,  0.17620937,  0.57835738,  0.17421608,  0.2297452 ,\n",
       "        0.88017259,  0.1541349 ,  0.24802069,  0.72918729,  0.60845846,\n",
       "        0.48126674,  0.07751097,  0.12224184,  0.15768488,  0.23004087,\n",
       "        0.29930689,  0.90850708,  0.13114185,  0.39879904])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy metrics for logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779220779221\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "# y_test is the actual class, y_pred_class is the predicted, and we can see the accuracy rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 285    0\n",
      "101    0\n",
      "581    0\n",
      "352    0\n",
      "726    0\n",
      "472    0\n",
      "233    0\n",
      "385    0\n",
      "556    0\n",
      "59     0\n",
      "756    0\n",
      "341    0\n",
      "445    1\n",
      "614    1\n",
      "371    0\n",
      "355    1\n",
      "19     1\n",
      "711    0\n",
      "430    0\n",
      "117    0\n",
      "Name: label, dtype: int64\n",
      "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "Prob: [ 0.44203825  0.37920023  0.23397337  0.06048765  0.22660355  0.27505632\n",
      "  0.37538901  0.17940593  0.16629588  0.21650141  0.41405121  0.10483651\n",
      "  0.93398949  0.68959899  0.08557689  0.67203211  0.2442347   0.31985908\n",
      "  0.27401652  0.22544739]\n"
     ]
    }
   ],
   "source": [
    "# print the first 20 actual and predicted responses\n",
    "print('True:', y_test[0:20])\n",
    "print('Pred:', y_pred_class[0:20])\n",
    "print('Prob:', y_pred_prob[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** IMPORTANT: \n",
    "*** First argument is actual values, second argument is predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  9]\n",
      " [25 30]]\n"
     ]
    }
   ],
   "source": [
    "# save confusion matrix and slice it into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#          Prediction\n",
    "#          TN     FP   TN+FP\n",
    "# Actual   FN     TP   FN+TP\n",
    "#        TN+FN   FP+TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779220779221\n",
      "0.779220779221\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy Metrics computed from a confusion matrix\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545454545455\n",
      "0.545454545455\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy TP rate\n",
    "# Recall is \"What percentage of we predicted correctly\"\n",
    "print(TP / float(TP + FN))  # (TP + FN): Because Predicted False Negative = Actual Positive\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769230769231\n",
      "0.769230769231\n"
     ]
    }
   ],
   "source": [
    "# Precision is \"Of positive class, what percentage are actually positive\"\n",
    "print(TP / float(TP + FP)) \n",
    "         # (TP + FP): because FP is predicted is Positive, but actual is Negative\n",
    "         # (TP + FP) could be total 1 in predicted class\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves and Area Under the Curve (AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** IMPORTANT: \n",
    "*** First argument is actual values, second argument is predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.02020202  0.02020202  0.06060606  0.06060606  0.07070707\n",
      "  0.07070707  0.09090909  0.09090909]\n",
      "[ 0.32727273  0.32727273  0.43636364  0.43636364  0.45454545  0.45454545\n",
      "  0.49090909  0.49090909  0.56363636]\n",
      "[ 0.67203211  0.6417145   0.60470835  0.57835738  0.56858336  0.55543825\n",
      "  0.54635693  0.52209502  0.49496165]\n"
     ]
    }
   ],
   "source": [
    "print(fpr[1:10])\n",
    "print(tpr[1:10])\n",
    "print(thresholds[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Clacluate AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823875114784\n"
     ]
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAElCAYAAAD6NKUrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1f15d208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier\\n AUC={auc}'.format(auc=metrics.roc_auc_score(y_test, y_pred_prob)))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.690909090909\n",
      "False Positive Rate: 0.222222222222\n",
      "Accuracy: 0.746753246753\n",
      "True Positive Rate: 0.490909090909\n",
      "False Positive Rate: 0.0909090909091\n",
      "Accuracy: 0.779220779221\n"
     ]
    }
   ],
   "source": [
    "# define a function that accepts a threshold and prints TP and FP rates\n",
    "def evaluate_threshold(threshold):\n",
    "    print('True Positive Rate:', tpr[thresholds > threshold][-1])\n",
    "    print('False Positive Rate:', fpr[thresholds > threshold][-1])\n",
    "    y_pred_class = binarize([y_pred_prob], threshold)[0]\n",
    "    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "evaluate_threshold(0.35)\n",
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823875114784\n"
     ]
    }
   ],
   "source": [
    "# AUC is the percentage of the ROC plot that is underneath the curve:\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "Advantages of cross-validation:\n",
    "\n",
    "1. More accurate estimate of test error\n",
    "2. More \"efficient\" use of data (every observation is used for both training and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78222222  0.79925926  0.83333333  0.77777778  0.8         0.84740741\n",
      "  0.81555556  0.90666667  0.85692308  0.82769231]\n",
      "0.824683760684\n",
      "0.0370175254325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())\n",
    "print(cv_scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
